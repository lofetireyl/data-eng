version: "3.9"

networks:
  stack:

services:
  zookeeper:
    networks: [stack]
    image: confluentinc/cp-zookeeper:7.6.1
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "echo ruok | nc -w 2 localhost 2181 | grep imok >/dev/null"]
      interval: 10s
      timeout: 5s
      retries: 12

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    depends_on: [zookeeper]
    networks: [stack]
    ports:
      - "9092:9092"   
      - "29092:29092" 
    restart: unless-stopped
    volumes:
      - kafka_data:/var/lib/kafka/data
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_HEAP_OPTS: "-Xms512m -Xmx1g"
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_RETENTION_BYTES: 268435456    
      KAFKA_LOG_SEGMENT_BYTES: 134217728
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_LOG_CLEANER_THREADS: 1
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 30
      start_period: 30s

  kafka-init:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka-init
    networks: [stack]
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP: kafka:29092
    volumes:
      - ./scripts/create-topics.sh:/app/create-topics.sh:ro
    entrypoint: ["/bin/bash","-lc","/app/create-topics.sh"]
    restart: "no"

  postgres:
    image: postgres:16
    container_name: postgres
    networks: [stack]
    environment:
      POSTGRES_DB: spotify
      POSTGRES_USER: spotify
      POSTGRES_PASSWORD: spotify
    ports:
      - "5432:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data
      - ./db/init.sql:/docker-entrypoint-initdb.d/01-schema.sql:ro

  producer:
    build: ./producer
    container_name: spotify-producer
    networks: [stack]
    dns:
      - 1.1.1.1
      - 8.8.8.8
    depends_on: 
      kafka: 
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP: kafka:29092
      SPOTIFY_CLIENT_ID: ${SPOTIFY_CLIENT_ID}
      SPOTIFY_CLIENT_SECRET: ${SPOTIFY_CLIENT_SECRET}
      MARKETS: AT
      POLL_SEC: "3600"
      FETCH_ARTISTS: "1"

    restart: unless-stopped

  adminer:
    image: adminer:4
    networks: [stack]
    depends_on: [postgres]
    ports:
      - "8081:8080"
    restart: unless-stopped

  getsongbpm-worker:
    build:
      context: ./getsongbpm_worker
    networks: [stack]
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - KAFKA_BOOTSTRAP=kafka:29092
      - IN_TOPIC=spotify.artist_meta
      - OUT_TOPIC=spotify.artist_bpm_meta
      - GROUP_ID=getsongbpm-workers
      - GETSONG_BASE_URL=https://api.getsong.co
      - GETSONG_API_KEY=${GETSONG_API_KEY}
      - LIMIT_PER_CALL=50
      - SLEEP_BETWEEN_PREFIX=0.5
      - DEDUP_TTL_SEC=30
    restart: unless-stopped

  spark:
    image: spark:3.5.1-python3
    container_name: spark
    user: root
    depends_on: [kafka, postgres]
    working_dir: /app
    networks: [stack]
    dns:
      - 1.1.1.1
      - 8.8.8.8
    volumes:
      - ./spark:/app
      - spark_checkpoints:/checkpoints
    restart: unless-stopped
    environment:
      KAFKA_BOOTSTRAP: kafka:29092
      PG_URL: jdbc:postgresql://postgres:5432/spotify
      PG_HOST: postgres
      PG_DB: spotify
      PG_USER: spotify
      PG_PASSWORD: spotify
      CHECKPOINT_DIR: /checkpoints
      SPARK_DRIVER_MEMORY: 6g
    command: [
      "/bin/bash","-lc",
      "pip install --no-cache-dir psycopg2-binary==2.9.9 pandas==1.5.3 && \
       /opt/spark/bin/spark-submit \
         --master local[*] \
         --driver-memory ${SPARK_DRIVER_MEMORY:-6g} \
         --conf spark.sql.session.timeZone=UTC \
         --conf spark.sql.shuffle.partitions=4 \
         --conf spark.sql.streaming.stateStore.maintenanceInterval=60s \
         --conf spark.sql.streaming.stateStore.providerClass=org.apache.spark.sql.execution.streaming.state.RocksDBStateStoreProvider \
         --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.postgresql:postgresql:42.7.4 \
         /app/job.py"
    ]
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f 'spark-submit|job.py' >/dev/null || exit 1"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s

  streamlit:
    build: ./streamlit
    container_name: streamlit
    depends_on:
      postgres:
        condition: service_started
    networks: [stack]
    ports:
      - "8501:8501"
    environment:
      PG_HOST: postgres 
      PG_PORT: "5432"
      PG_DB: spotify
      PG_USER: spotify
      PG_PASSWORD: spotify
    volumes:
      - ./streamlit/app_streamlit.py:/app/app_streamlit.py:ro
    restart: unless-stopped      

volumes:
  kafka_data:
  pg_data:
  spark_checkpoints:
